<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.6.2" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.6.2" type="image/png" sizes="32x32"><meta name="description" content="Mini-batch Stochastic gradient descent(SGD)                             适用范围        小批量随机梯度下降是整个深度学习里面，目前来说几乎是唯一求解的办法 在机器学习里面可以解决除开决策树之外所有模型的求解(例如SVM,Logistic Regression)">
<meta property="og:type" content="article">
<meta property="og:title" content="小批量随机梯度下降">
<meta property="og:url" content="http://example.com/2022/05/23/%E5%B0%8F%E6%89%B9%E9%87%8F%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Mini-batch Stochastic gradient descent(SGD)                             适用范围        小批量随机梯度下降是整个深度学习里面，目前来说几乎是唯一求解的办法 在机器学习里面可以解决除开决策树之外所有模型的求解(例如SVM,Logistic Regression)">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-05-23T12:29:30.000Z">
<meta property="article:modified_time" content="2022-05-25T13:03:17.819Z">
<meta property="article:author" content="Yang">
<meta property="article:tag" content="机器学习优化方法">
<meta name="twitter:card" content="summary"><title>小批量随机梯度下降 | Hexo</title><link ref="canonical" href="http://example.com/2022/05/23/%E5%B0%8F%E6%89%B9%E9%87%8F%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.6.2"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"复制","copySuccess":"复制成功","copyError":"复制失败"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 6.2.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">首页</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">归档</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">Hexo</div><div class="header-banner-info__subtitle"></div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">小批量随机梯度下降</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2022-05-23</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2022-05-25</span></span></div></header><div class="post-body">
        <h1 id="mini-batch-stochastic-gradient-descentsgd"   >
          <a href="#mini-batch-stochastic-gradient-descentsgd" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#mini-batch-stochastic-gradient-descentsgd"></a> Mini-batch Stochastic gradient descent(SGD)</h1>
      

        <h2 id="适用范围"   >
          <a href="#适用范围" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#适用范围"></a> 适用范围</h2>
      
<p>小批量随机梯度下降是整个深度学习里面，目前来说几乎是唯一求解的办法</p>
<p>在机器学习里面可以解决除开决策树之外所有模型的求解(例如SVM,Logistic Regression)</p>

        <h2 id="算法流程"   >
          <a href="#算法流程" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#算法流程"></a> 算法流程</h2>
      
<hr />
<ul>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>Train by mini-batch SGD (by various other ways as well)</mtext></mrow><annotation encoding="application/x-tex">\text {Train by mini-batch SGD (by various other ways as well)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Train by mini-batch SGD (by various other ways as well)</span></span></span></span></span>
<ul>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext> w model param, </mtext><mi>b</mi><mtext> batch size, </mtext><msub><mi>η</mi><mi>t</mi></msub><mtext> learning rate at time </mtext><mi>t</mi></mrow><annotation encoding="application/x-tex">\text { w model param, } b \text { batch size, } \eta_{t} \text { learning rate at time } t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord text"><span class="mord"> w model param, </span></span><span class="mord mathdefault">b</span><span class="mord text"><span class="mord"> batch size, </span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord text"><span class="mord"> learning rate at time </span></span><span class="mord mathdefault">t</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext> Randomly initialize </mtext><msub><mi mathvariant="bold">w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\text { Randomly initialize } \mathbf{w}_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord text"><span class="mord"> Randomly initialize </span></span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">w</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext> Repeat </mtext><mi>t</mi><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mo>…</mo><mtext> until converge </mtext></mrow><annotation encoding="application/x-tex">\text { Repeat } t=1,2, \ldots \text { until converge }</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord text"><span class="mord"> Repeat </span></span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord"> until converge </span></span></span></span></span>
<ul>
<li>$Randomly samples  I_{t} \subset{1, \ldots, n}  with  \left|I_{t}\right|=b  $</li>
<li>$\text {Update}  \mathbf{w}<em>{t+1}=\mathbf{w}</em>{t}-\eta_{t} \nabla_{\mathbf{w}<em>{t}} \ell\left(\mathbf{X}</em>{I_{t}}, \mathbf{y}<em>{I</em>{t}}, \mathbf{w}_{t}\right) $</li>
</ul>
</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext> Pros: solve all objectives in this course except for trees </mtext></mrow><annotation encoding="application/x-tex">\text { Pros: solve all objectives in this course except for trees }</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord text"><span class="mord"> Pros: solve all objectives in this course except for trees </span></span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext> Cons: sensitive to hyper-parameters </mtext><mi>b</mi><mtext> and </mtext><msub><mi>η</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\text { Cons: sensitive to hyper-parameters } b \text { and } \eta_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord text"><span class="mord"> Cons: sensitive to hyper-parameters </span></span><span class="mord mathdefault">b</span><span class="mord text"><span class="mord"> and </span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
</ul>
</li>
</ul>
<hr />
<ul>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="bold">w</mi><mtext> 是模型的参数，包括线性模型的 </mtext><mi mathvariant="normal">w</mi><mtext> (权重)和 </mtext><mi mathvariant="normal">b</mi><mtext> (偏移) 在输入的特征里面加入一列全为1的特征</mtext></mrow><annotation encoding="application/x-tex">\mathbf{w} \text { 是模型的参数，包括线性模型的 } \mathrm{w} \text { (权重)和 } \mathrm{b} \text { (偏移) }\text {在输入的特征里面加入一列全为1的特征}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">w</span></span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">是模型的参数，包括线性模型的</span><span class="mord"> </span></span><span class="mord"><span class="mord mathrm" style="margin-right:0.01389em;">w</span></span><span class="mord text"><span class="mord"> (</span><span class="mord cjk_fallback">权重</span><span class="mord">)</span><span class="mord cjk_fallback">和</span><span class="mord"> </span></span><span class="mord"><span class="mord mathrm">b</span></span><span class="mord text"><span class="mord"> (</span><span class="mord cjk_fallback">偏移</span><span class="mord">) </span></span><span class="mord text"><span class="mord cjk_fallback">在输入的特征里面加入一列全为</span><span class="mord">1</span><span class="mord cjk_fallback">的特征</span></span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="bold">b</mi><mtext> 表示批量大小</mtext></mrow><annotation encoding="application/x-tex">\mathbf{b} \text { 表示批量大小}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">b</span></span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">表示批量大小</span></span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>η</mi><mi>t</mi></msub><mtext> 表示在t时刻的学习率</mtext></mrow><annotation encoding="application/x-tex">\eta_{t}  \text { 表示在t时刻的学习率}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">表示在</span><span class="mord">t</span><span class="mord cjk_fallback">时刻的学习率</span></span></span></span></span>
<ul>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>在1时刻(初始时刻)随机初始化</mtext><msub><mi mathvariant="bold">w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\text{在1时刻(初始时刻)随机初始化}\mathbf{w}_{1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord cjk_fallback">在</span><span class="mord">1</span><span class="mord cjk_fallback">时刻</span><span class="mord">(</span><span class="mord cjk_fallback">初始时刻</span><span class="mord">)</span><span class="mord cjk_fallback">随机初始化</span></span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">w</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>持续迭代</mtext><mi>t</mi><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mo>…</mo><mtext>直至模型收敛(收敛条件:)</mtext></mrow><annotation encoding="application/x-tex">\text{持续迭代} t=1,2, \ldots\text{直至模型收敛(收敛条件:)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord cjk_fallback">持续迭代</span></span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord cjk_fallback">直至模型收敛</span><span class="mord">(</span><span class="mord cjk_fallback">收敛条件</span><span class="mord">:)</span></span></span></span></span>
<ul>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>每次迭代从样本中随机选取</mtext><msub><mi>I</mi><mi>t</mi></msub><mo>⊂</mo><mo stretchy="false">{</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">}</mo><mi mathvariant="normal">个</mi><mi mathvariant="normal">样</mi><mi mathvariant="normal">本</mi><mi mathvariant="normal">，</mi><mi mathvariant="normal">选</mi><mi mathvariant="normal">取</mi><mi mathvariant="normal">样</mi><mi mathvariant="normal">本</mi><mi mathvariant="normal">数</mi><mi mathvariant="normal">目</mi><mi mathvariant="normal">为</mi><mrow><mo fence="true">∣</mo><msub><mi>I</mi><mi>t</mi></msub><mo fence="true">∣</mo></mrow><mo>=</mo><mi>b</mi><mo stretchy="false">(</mo><mi mathvariant="normal">批</mi><mi mathvariant="normal">量</mi><mi mathvariant="normal">大</mi><mi mathvariant="normal">小</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{每次迭代从样本中随机选取} I_{t} \subset\{1, \ldots, n\}个样本，选取样本数目为\left|I_{t}\right|=b(批量大小)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord text"><span class="mord cjk_fallback">每次迭代从样本中随机选取</span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">⊂</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">n</span><span class="mclose">}</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">样</span><span class="mord cjk_fallback">本</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">选</span><span class="mord cjk_fallback">取</span><span class="mord cjk_fallback">样</span><span class="mord cjk_fallback">本</span><span class="mord cjk_fallback">数</span><span class="mord cjk_fallback">目</span><span class="mord cjk_fallback">为</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">∣</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">b</span><span class="mopen">(</span><span class="mord cjk_fallback">批</span><span class="mord cjk_fallback">量</span><span class="mord cjk_fallback">大</span><span class="mord cjk_fallback">小</span><span class="mclose">)</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>更新</mtext><mi mathvariant="bold">w</mi><mo separator="true">,</mo><mi mathvariant="normal">进</mi><mi mathvariant="normal">入</mi><mi mathvariant="normal">下</mi><mi mathvariant="normal">一</mi><mi mathvariant="normal">次</mi><mi mathvariant="normal">迭</mi><mi mathvariant="normal">代</mi><mi mathvariant="normal">的</mi><mi mathvariant="bold">w</mi><mi mathvariant="normal">为</mi><mo>:</mo><msub><mi mathvariant="bold">w</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi mathvariant="bold">w</mi><mi>t</mi></msub><mo>−</mo><msub><mi>η</mi><mi>t</mi></msub><msub><mi mathvariant="normal">∇</mi><msub><mi mathvariant="bold">w</mi><mi>t</mi></msub></msub><mi mathvariant="normal">ℓ</mi><mrow><mo fence="true">(</mo><msub><mi mathvariant="bold">X</mi><msub><mi>I</mi><mi>t</mi></msub></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">y</mi><msub><mi>I</mi><mi>t</mi></msub></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">w</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{更新}\mathbf{w},进入下一次迭代的\mathbf{w}为: \mathbf{w}_{t+1}=\mathbf{w}_{t}-\eta_{t} \nabla_{\mathbf{w}_{t}} \ell\left(\mathbf{X}_{I_{t}}, \mathbf{y}_{I_{t}}, \mathbf{w}_{t}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord text"><span class="mord cjk_fallback">更新</span></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">w</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord cjk_fallback">进</span><span class="mord cjk_fallback">入</span><span class="mord cjk_fallback">下</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">次</span><span class="mord cjk_fallback">迭</span><span class="mord cjk_fallback">代</span><span class="mord cjk_fallback">的</span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">w</span></span><span class="mord cjk_fallback">为</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.652771em;vertical-align:-0.208331em;"></span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">w</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">w</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.0001em;vertical-align:-0.2501em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16110799999999997em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathbf mtight" style="margin-right:0.01597em;">w</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.29634285714285713em;"><span style="top:-2.357em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mord">ℓ</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord"><span class="mord mathbf">X</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.29634285714285713em;"><span style="top:-2.357em;margin-left:-0.07847em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">y</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.29634285714285713em;"><span style="top:-2.357em;margin-left:-0.07847em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">w</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span></li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>优点：小批量随机梯度下降可以解决出决策树以外的模型</mtext></mrow><annotation encoding="application/x-tex">\text{优点：小批量随机梯度下降可以解决出决策树以外的模型}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord cjk_fallback">优点：小批量随机梯度下降可以解决出决策树以外的模型</span></span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>缺点：超参数</mtext><mi mathvariant="bold">b</mi><mi mathvariant="normal">和</mi><mi>η</mi><mi mathvariant="normal">需</mi><mi mathvariant="normal">要</mi><mi mathvariant="normal">自</mi><mi mathvariant="normal">己</mi><mi mathvariant="normal">设</mi><mi mathvariant="normal">置</mi><mo stretchy="false">(</mo><mi mathvariant="normal">难</mi><mi mathvariant="normal">调</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{缺点：超参数}\mathbf{b}和\eta需要自己设置(难调)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord cjk_fallback">缺点：超参数</span></span><span class="mord"><span class="mord mathbf">b</span></span><span class="mord cjk_fallback">和</span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mord cjk_fallback">需</span><span class="mord cjk_fallback">要</span><span class="mord cjk_fallback">自</span><span class="mord cjk_fallback">己</span><span class="mord cjk_fallback">设</span><span class="mord cjk_fallback">置</span><span class="mopen">(</span><span class="mord cjk_fallback">难</span><span class="mord cjk_fallback">调</span><span class="mclose">)</span></span></span></span></li>
</ul>
<hr />

        <h2 id="实现代码"   >
          <a href="#实现代码" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#实现代码"></a> 实现代码</h2>
      
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">from</span> IPython <span class="keyword">import</span> display</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> autograd, nd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="comment"># 生成数据集</span></span><br><span class="line">num_inputs = <span class="number">2</span>   <span class="comment">#数据维度</span></span><br><span class="line">num_examples = <span class="number">1000</span>   <span class="comment"># 样本个数</span></span><br><span class="line">true_w = [<span class="number">2</span>, -<span class="number">3.4</span>]  <span class="comment"># 权重初始值</span></span><br><span class="line">true_b = <span class="number">4.2</span>  <span class="comment"># 偏置初始值</span></span><br><span class="line">features = nd.random.normal(scale = <span class="number">1</span>,shape=(num_examples, num_inputs))</span><br><span class="line">labels = true_w[<span class="number">0</span>]*features[:,<span class="number">0</span>]+true_w[<span class="number">1</span>]*features[:,<span class="number">1</span>]+true_b</span><br><span class="line">labels += nd.random.normal(loc = <span class="number">0</span>,scale = <span class="number">0.01</span>, shape=labels.shape) </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_iter</span>(<span class="params">batch_size, features, labels</span>):</span><br><span class="line">    num_examples = <span class="built_in">len</span>(features)</span><br><span class="line">    indices = <span class="built_in">list</span>(<span class="built_in">range</span>(num_examples))</span><br><span class="line">    random.shuffle(indices) <span class="comment"># 打乱标号</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_examples, batch_size):</span><br><span class="line">        <span class="comment">#从i到min(i+i+batch_size(一个批量), num_exmaples(不够整分就直接拿去全部))</span></span><br><span class="line">        j = nd.array(indices[i : <span class="built_in">min</span>(i+batch_size, num_examples) ] ) </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">yield</span> features.take(j), labels.take(j) <span class="comment"># take根据索引返回对应元素</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 初始化模型参数</span></span><br><span class="line">w = nd.random.normal(scale = <span class="number">0.01</span>, shape=(num_inputs,<span class="number">1</span>))<span class="comment"># num_inputs(输出维度),1的维度</span></span><br><span class="line">b = nd.zeros(shape = (<span class="number">1</span>,))<span class="comment"># 1,表示张量</span></span><br><span class="line"><span class="comment"># 开辟梯度空间</span></span><br><span class="line">w.attach_grad()</span><br><span class="line">b.attach_grad()</span><br><span class="line"><span class="comment"># 定义损失函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">squared_loss</span>(<span class="params">y_hat, y</span>):</span><br><span class="line">    <span class="keyword">return</span> (y_hat-y.reshape(y_hat.shape))**<span class="number">2</span>/<span class="number">2</span></span><br><span class="line"><span class="comment"># 优化方法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sgd</span>(<span class="params">params, lr, batch_size</span>):</span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">        param[:] = param - lr*param.grad/batch_size</span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">lr = <span class="number">0.03</span></span><br><span class="line">num_epochs = <span class="number">3</span></span><br><span class="line">net = linreg</span><br><span class="line">loss = squared_loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter(batch_size, features, labels):</span><br><span class="line">        <span class="keyword">with</span> autograd.record():</span><br><span class="line">            l = loss(net(X,w,b),y)</span><br><span class="line">        l.backward()</span><br><span class="line">        sgd([w,b],lr,batch_size)</span><br><span class="line">    train_l = loss(net(features, w, b), labels)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;epoch %d, loss %f&#x27;</span>%(epoch+<span class="number">1</span>,train_l.mean().asnumpy()))</span><br></pre></td></tr></table></div></figure>

        <h2 id="参考"   >
          <a href="#参考" class="heading-link"><i class="fas fa-link"></i></a><a class="markdownIt-Anchor" href="#参考"></a> 参考:</h2>
      
<ul>
<li><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1234y1m75j" >https://www.bilibili.com/video/BV1234y1m75j</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></li>
<li><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://www.bilibili.com/read/cv13723919?from=note" >https://www.bilibili.com/read/cv13723919?from=note</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></li>
<li><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://zh.d2l.ai/chapter_linear-networks/linear-regression-scratch.html" >https://zh.d2l.ai/chapter_linear-networks/linear-regression-scratch.html</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></li>
</ul>
</div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ 本文结束，感谢您的阅读 ------</div></div><div class="post-copyright copyright"><div class="copyright-author"><span class="copyright-author__name">本文作者: </span><span class="copyright-author__value"><a href="http://example.com">Yang</a></span></div><div class="copyright-link"><span class="copyright-link__name">本文链接: </span><span class="copyright-link__value"><a href="http://example.com/2022/05/23/%E5%B0%8F%E6%89%B9%E9%87%8F%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/">http://example.com/2022/05/23/%E5%B0%8F%E6%89%B9%E9%87%8F%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/</a></span></div><div class="copyright-notice"><span class="copyright-notice__name">版权声明: </span><span class="copyright-notice__value">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> 许可协议。转载请注明出处！</span></div></div><div class="post-tags"><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/">机器学习优化方法</a></span></div><nav class="post-paginator paginator"><div class="paginator-prev"><a class="paginator-prev__link" href="/2022/05/23/123/"><span class="paginator-prev__icon"><i class="fas fa-angle-left"></i></span><span class="paginator-prev__text">123</span></a></div><div class="paginator-next"><a class="paginator-next__link" href="/2022/05/17/hello-world/"><span class="paginator-prev__text">Hello World</span><span class="paginator-next__icon"><i class="fas fa-angle-right"></i></span></a></div></nav></footer></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">文章目录</span><span class="sidebar-nav-ov">站点概览</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#mini-batch-stochastic-gradient-descentsgd"><span class="toc-number">1.</span> <span class="toc-text">
           Mini-batch Stochastic gradient descent(SGD)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%82%E7%94%A8%E8%8C%83%E5%9B%B4"><span class="toc-number">1.1.</span> <span class="toc-text">
           适用范围</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="toc-number">1.2.</span> <span class="toc-text">
           算法流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81"><span class="toc-number">1.3.</span> <span class="toc-text">
           实现代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-number">1.4.</span> <span class="toc-text">
           参考:</span></a></li></ol></li></ol></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/icons/stun-logo.svg" alt="avatar"></div><p class="sidebar-ov-author__text">hello world</p></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">4</div><div class="sidebar-ov-state-item__name">归档</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="知识共享许可协议" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">你已阅读了 </span><span class="sidebar-reading-info__num">0</span><span class="sidebar-reading-info__perc">%</span></div><div class="sidebar-reading-line"></div></div></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2022</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>Yang</span></div><div><span>由 <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a> 强力驱动</span><span> v6.2.0</span><span class="footer__devider">|</span><span>主题 - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.6.2</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><link href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" rel="stylesheet" type="text/css"><link href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/copy-tex.css" rel="stylesheet" type="text/css"><script src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/copy-tex.min.js"></script><script src="/js/utils.js?v=2.6.2"></script><script src="/js/stun-boot.js?v=2.6.2"></script><script src="/js/scroll.js?v=2.6.2"></script><script src="/js/header.js?v=2.6.2"></script><script src="/js/sidebar.js?v=2.6.2"></script></body></html>