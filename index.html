<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.11.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/./public/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Yang">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Hexo</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Hexo</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Yang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">15</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/03/14/%E5%99%AA%E5%A3%B0%E7%BB%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/03/14/%E5%99%AA%E5%A3%B0%E7%BB%84/" class="post-title-link" itemprop="url">处理恶意数据和带噪声的数据相关研究搜集(部分)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-03-14 19:26:48" itemprop="dateCreated datePublished" datetime="2023-03-14T19:26:48+08:00">2023-03-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-03-15 16:28:53" itemprop="dateModified" datetime="2023-03-15T16:28:53+08:00">2023-03-15</time>
    </span>

  
    <span id="/2023/03/14/%E5%99%AA%E5%A3%B0%E7%BB%84/" class="post-meta-item leancloud_visitors" data-flag-title="处理恶意数据和带噪声的数据相关研究搜集(部分)" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span class="leancloud-visitors-count"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="处理恶意数据和带噪声的数据相关研究搜集部分">处理恶意数据和带噪声的数据相关研究搜集(部分)</h1>
<h2 id="mixup-beyond-empirical-risk-minimization">mixup: Beyond Empirical Risk Minimization</h2>
<p>地址:https://arxiv.org/abs/1710.09412</p>
<table>
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>author</th>
<th>introduction</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, David Lopez-Paz</td>
<td>Large deep neural networks are powerful, but exhibit undesirable behaviors such as memorization and sensitivity to adversarial examples. In this work, we propose mixup, a simple learning principle to alleviate these issues. In essence, mixup trains a neural network on convex combinations of pairs of examples and their labels. By doing so, mixup regularizes the neural network to favor simple linear behavior in-between training examples. Our experiments on the ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show that mixup improves the generalization of state-of-the-art neural network architectures. We also find that mixup reduces the memorization of corrupt labels, increases the robustness to adversarial examples, and stabilizes the training of generative adversarial networks.</td>
</tr>
<tr class="even">
<td></td>
<td>大型深度神经网络功能强大，但表现出不良行为 比如记忆和对对抗性例子的敏感性。在这项工作中，我们提出混淆，一个简单的学习原则来缓解这些问题。在从本质上讲，Mixup 在 示例及其标签。通过这样做，混淆将神经网络正则化为 支持训练示例之间的简单线性行为。我们的实验 ImageNet-2012、CIFAR-10、CIFAR-100、Google 命令和 UCI 数据集显示 这种混淆改善了最先进的神经网络的泛化。 架构。我们还发现，混淆减少了对腐败的记忆 标签，增加对抗性示例的鲁棒性，并稳定 生成对抗网络的训练。</td>
</tr>
</tbody>
</table>
<h2 id="mentornet-learning-data-driven-curriculum-for-very-deep-neural-networks-on-corrupted-labels">MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels</h2>
<p>地址:https://arxiv.org/abs/1712.05055</p>
<table>
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>author</th>
<th>introduction</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, Li Fei-Fei</td>
<td>Recent deep networks are capable of memorizing the entire data even when the labels are completely random. To overcome the overfitting on corrupted labels, we propose a novel technique of learning another neural network, called MentorNet, to supervise the training of the base deep networks, namely, StudentNet. During training, MentorNet provides a curriculum (sample weighting scheme) for StudentNet to focus on the sample the label of which is probably correct. Unlike the existing curriculum that is usually predefined by human experts, MentorNet learns a data-driven curriculum dynamically with StudentNet. Experimental results demonstrate that our approach can significantly improve the generalization performance of deep networks trained on corrupted training data. Notably, to the best of our knowledge, we achieve the best-published result on WebVision, a large benchmark containing 2.2 million images of real-world noisy labels. The code are at this https URL</td>
</tr>
<tr class="even">
<td></td>
<td>最近的深度网络能够记住整个数据，即使 标签是完全随机的。为了克服损坏标签上的过度拟合， 我们提出了一种学习另一种神经网络的新技术，称为 MentorNet，监督基础深度网络的培训，即 学生网.在培训期间，导师网提供课程（样本加权 方案）让学生网专注于样本，其标签可能是 正确。与通常由人类预定义的现有课程不同 专家，MentorNet通过StudentNet动态学习数据驱动的课程。 实验结果表明，我们的方法可以显著提高 在损坏训练上训练的深度网络的泛化性能 数据。值得注意的是，据我们所知，我们取得了最好的出版成果 WebVision 上的结果，这是一个包含 2 万张图像的大型基准测试 现实世界的嘈杂标签。</td>
</tr>
</tbody>
</table>
<p>代码:https://github.com/google/mentornet</p>
<h2 id="beyond-synthetic-noise-deep-learning-on-controlled-noisy-labels">Beyond Synthetic Noise: Deep Learning on Controlled Noisy Labels</h2>
<p>地址:https://arxiv.org/abs/1911.09781</p>
<table>
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>author</th>
<th>introduction</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Lu Jiang, Di Huang, Mason Liu, Weilong Yang</td>
<td>Performing controlled experiments on noisy data is essential in understanding deep learning across noise levels. Due to the lack of suitable datasets, previous research has only examined deep learning on controlled synthetic label noise, and real-world label noise has never been studied in a controlled setting. This paper makes three contributions. First, we establish the first benchmark of controlled real-world label noise from the web. This new benchmark enables us to study the web label noise in a controlled setting for the first time. The second contribution is a simple but effective method to overcome both synthetic and real noisy labels. We show that our method achieves the best result on our dataset as well as on two public benchmarks (CIFAR and WebVision). Third, we conduct the largest study by far into understanding deep neural networks trained on noisy labels across different noise levels, noise types, network architectures, and training settings. The data and code are released at the following link: this http URL</td>
</tr>
<tr class="even">
<td></td>
<td>对嘈杂数据进行对照实验对于理解至关重要 跨噪声水平的深度学习。由于缺乏合适的数据集， 以前的研究只研究了受控合成标签上的深度学习 噪声和现实世界的标签噪声从未在受控环境中进行过研究 设置。本文有三点贡献。首先，我们建立第一个 来自网络的真实世界标签噪声的受控基准。这个新的基准 使我们能够首次在受控设置中研究网络标签噪声 时间。第二个贡献是克服两者的简单但有效的方法 合成和真正的嘈杂标签。我们证明我们的方法实现了最好的 在我们的数据集以及两个公共基准（CIFAR和 网络视觉）。第三，我们进行了迄今为止规模最大的研究，以深入了解 在不同噪声水平的噪声标签上训练神经网络，噪声 类型、网络体系结构和训练设置。</td>
</tr>
</tbody>
</table>
<p>代码:http://www.lujiang.info/cnlw.html</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/02/24/ChatGPT-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/02/24/ChatGPT-1/" class="post-title-link" itemprop="url">ChatGPT-1</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-02-24 00:45:09" itemprop="dateCreated datePublished" datetime="2023-02-24T00:45:09+08:00">2023-02-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-03-15 16:26:40" itemprop="dateModified" datetime="2023-03-15T16:26:40+08:00">2023-03-15</time>
    </span>

  
    <span id="/2023/02/24/ChatGPT-1/" class="post-meta-item leancloud_visitors" data-flag-title="ChatGPT-1" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span class="leancloud-visitors-count"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/10/28/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/10/28/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">序列模型</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-10-28 19:26:48" itemprop="dateCreated datePublished" datetime="2022-10-28T19:26:48+08:00">2022-10-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-03-15 16:26:40" itemprop="dateModified" datetime="2023-03-15T16:26:40+08:00">2023-03-15</time>
    </span>

  
    <span id="/2022/10/28/%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/" class="post-meta-item leancloud_visitors" data-flag-title="序列模型" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span class="leancloud-visitors-count"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="序列问题的模型建立">序列问题的模型建立</h2>
<p>在时间<span class="math inline">\(t\)</span>观察到<span class="math inline">\(x_t\)</span>，那么得到<span class="math inline">\(T\)</span>个不独立的随机变量<span class="math inline">\((x_1,...,x_T) \sim p(\mathbf{x})\)</span></p>
<p>联合概率可以用条件概率展开</p>
<h3 id="条件概率公式">条件概率公式</h3>
<p><span class="math display">\[p(a, b)=p(a) p(b \mid a)=p(b) p(a \mid b)\]</span></p>
<p>由于条件概率公式，可以得到<span class="math inline">\(p(\mathbf{x})\)</span></p>
<p><span class="math inline">\(p(\mathbf{x})=p(x_1)\cdot p(x_2|x_1)\cdot p(x_3|x_1,x_2)\cdot...p(x_T|x_1,x_2,...,x_{T-1})\)</span></p>
<p>或</p>
<p><span class="math inline">\(p(\mathbf{x})=p(x_T)\cdot p(x_{T-1}|x_T)\cdot p(x_{T-2}|x_{T-1},x_T)\cdot...p(x_1|x_2,x_3,...,x_{T})\)</span></p>
<p>以前项(1到t)为例</p>
<p>对于条件概率建模</p>
<p><span class="math display">\[p(x_t|x_1,...,x_{t-1})=p(x_t|f(x_1,...,x_{t-1}))\]</span></p>
<p>其中<span class="math inline">\(f(x_1,...,x_{t-1})\)</span>为对见过的数据建模，也称为自回归模型</p>
<h4 id="自回归模型">自回归模型</h4>
<p>用<span class="math inline">\(x_1\)</span>到<span class="math inline">\(x_{t-1}\)</span>来预测<span class="math inline">\(x_t\)</span>而不是用<span class="math inline">\(x\)</span>来预测<span class="math inline">\(y\)</span></p>
<h3 id="马尔科夫假设">马尔科夫假设</h3>
<p>假设当前数据只和<span class="math inline">\(\tau\)</span>个过去数据点相关</p>
<p><span class="math inline">\(p(x_t|x_1,...,x_{t-1})=p(x_t|x_{t-\tau},...,x_{t-1})=p(x_t|f(x_{t-\tau},...,x_{t-1}))\)</span></p>
<p>意图:<span class="math inline">\(\tau\)</span>的固定使得所计算的条件概率模型不会随着时间的增大而增大</p>
<p>例如:明天的股票可能和近几年相关，但是和十年前，二十年前关系可能不大；</p>
<h3 id="潜变量模型">潜变量模型</h3>
<p>引入潜变量<span class="math inline">\(h_t\)</span>来表示过去信息<span class="math inline">\(h_t=f(x_1,...,x_{t-1})\)</span></p>
<p>这样可以用<span class="math inline">\(\hat{x}_t=p(x_t|h_t)\)</span> 来估计<span class="math inline">\(x_t\)</span></p>
<p>及可将原问题模型拆解成:</p>
<ol type="1">
<li><span class="math inline">\(\hat{x}_t=P(x_t|h_t)\)</span></li>
<li><span class="math inline">\(h_t=g(h_{t-1},x_{t-1})\)</span></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/10/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/10/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/" class="post-title-link" itemprop="url">机器学习实战——读书笔记1</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-10-02 13:37:27" itemprop="dateCreated datePublished" datetime="2022-10-02T13:37:27+08:00">2022-10-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-10-07 15:26:22" itemprop="dateModified" datetime="2022-10-07T15:26:22+08:00">2022-10-07</time>
    </span>

  
    <span id="/2022/10/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/" class="post-meta-item leancloud_visitors" data-flag-title="机器学习实战——读书笔记1" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span class="leancloud-visitors-count"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>https://archive.ics.uci.edu/ml/machine-learning-databases/breast.cancer-wisconsin/breast-cancer-wisconsin.data</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/09/30/%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC-%E7%BB%83%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/09/30/%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC-%E7%BB%83%E4%B9%A0/" class="post-title-link" itemprop="url">公式推导-练习</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-09-30 10:45:37" itemprop="dateCreated datePublished" datetime="2022-09-30T10:45:37+08:00">2022-09-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-10-07 15:37:18" itemprop="dateModified" datetime="2022-10-07T15:37:18+08:00">2022-10-07</time>
    </span>

  
    <span id="/2022/09/30/%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC-%E7%BB%83%E4%B9%A0/" class="post-meta-item leancloud_visitors" data-flag-title="公式推导-练习" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span class="leancloud-visitors-count"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="第一问">第一问</h1>
<p>对于第一问来说，a c组与b d组的求解过程是对称的，只是对于系数符号有所变换，只需求解a d，b c只需要在所求解的结果上更改分母便可</p>
<p><span class="math display">\[
\begin{equation*}
\begin{aligned}
e&amp;=m_{1}a+m_{2}b \\
f&amp;=m_{3}a+m_{4}b\\
g&amp; = m_{1}c+m_{2}d\\
h&amp;=m_{3}c+m_{4}d\\
\\
a&amp;= n_{1}e+n_{2}f\\
b&amp;= n_{3}e+n_{4}f\\
c&amp;= n_{1}g+n_{2}h\\
d&amp;= n_{3}g+n_{4}h\\
\end{aligned}
\end{equation*}
\]</span> 由上式子可以推出 <span class="math display">\[
\begin{equation*}
\begin{aligned}
\\
a &amp;= (m_{2}n_{1} + m_{4}n_{2})b/(1 -m_{1}n_{1} - m_{3}n_{2})\\
b&amp;=(m_{1}n_{3} + m_{3}n_{4})a/(1 - m_{4}n_{4} - m_{2}n_{3})\\
c &amp;= (m_{2}n_{1} + m_{4}n_{2})d/(1 -m_{1}n_{1} - m_{3}n_{2})\\
d&amp;=(m_{1}n_{3} + m_{3}n_{4})c/(1 - m_{4}n_{4} - m_{2}n_{3})\\
\\
\end{aligned}
\end{equation*} 
\]</span> 将其带入<span class="math inline">\(z_{1}=ie+jf\)</span>、<span class="math inline">\(z_{2}=kg+lh\)</span>中 <span class="math display">\[
\begin{equation*}
\begin{aligned}
z_{1} &amp;= ie+jf\\
&amp;=i(m_{1}a+m_{2}b)+j(m_{3}a+m_{4}b)\\
&amp;=i(m_{1}a+m_{2}(m_{1}n_{3} + m_{3}n_{4})a/(1 - m_{4}n_{4} - m_{2}n_{3}))+j(m_{3}a+m_{4}(m_{1}n_{3} + m_{3}n_{4})a/(1 - m_{4}n_{4} - m_{2}n_{3}))\\
\\
\\
z_{2}&amp;=kg+lh\\
&amp;=k(m_{1}c+m_{2}d)+l(m_{3}c+m_{4}d)\\
&amp;=k(m_{1}(m_{2}n_{1} + m_{4}n_{2})d/(1 -m_{1}n_{1} - m_{3}n_{2})+m_{2}d)+l(m_{3}(m_{2}n_{1} + m_{4}n_{2})d/(1 -m_{1}n_{1} - m_{3}n_{2})+m_{4}d)
\end{aligned}
\end{equation*}
\]</span> 可解出<span class="math inline">\(a\)</span>,<span class="math inline">\(d\)</span>: <span class="math display">\[
\begin{equation*}
\begin{aligned}
a&amp;= z1/(i(m_{1} - (m_{2}(m_{1}n_{3} + m_{3}n_{4}))/(m_{2}n_{3} + m_{4}n_{4} - 1)) + j(m_{3} - (m_{4}(m_{1}n_{3} + m_{3}n_{4}))/(m_{2}n_{3} + m_{4}n_{4} - 1)))\\
d&amp;=z2/(k(m_{2} - (m_{1}(m_{2}n_{1} + m_{4}n_{2}))/(m_{1}n_{1} + m_{3}n_{2} - 1)) + l(m_{4} - (m_{3}(m_{2}n_{1} + m_{4}n_{2}))/(m_{1}n_{1} + m_{3}n_{2} - 1)))\\
\end{aligned}
\end{equation*}
\]</span></p>
<h1 id="第二问">第二问</h1>
<p><span class="math display">\[
\begin{equation*}
\begin{aligned}
z^{新}_{1}&amp;=ie+jg\\
&amp;=i(m_{1}a+m_{2}b)+j(m_{1}c+m_{2}d)\\
&amp;=i(m_{1}a+m_{2}(m_{1}n_{3} + m_{3}n_{4})a/(1 - m_{4}n_{4} - m_{2}n_{3}))+j(m_{1}c+m_{2}(m_{1}n_{3} + m_{3}n_{4})c/(1 - m_{4}n_{4} - m_{2}n_{3}))\\
&amp;= i(m_{1} - (m_{2}(m_{1}n_{3} + m_{3}n_{4}))/(m_{2}n_{3} + m_{4}n_{4} - 1))a + j(m_{1} - (m_{2}(m_{1}n_{3} + m_{3}n_{4}))/(m_{2}n_{3} + m_{4}n_{4} - 1))c\\
&amp;= (m_{1} - (m_{2}(m_{1}n_{3} + m_{3}n_{4}))/(m_{2}n_{3} + m_{4}n_{4} - 1))(ia+jc)\\
\\
z^{新}_{2}&amp;=kf+lh\\
&amp;=k(m_{3}a+m_{4}b)+l(m_{3}c+m_{4}d)\\
&amp;=k(m_{3}(m_{2}n_{1} + m_{4}n_{2})b/(1 -m_{1}n_{1} - m_{3}n_{2})+m_{4}b)+l(m_{3}(m_{2}n_{1} + m_{4}n_{2})d/(1 -m_{1}n_{1} - m_{3}n_{2})+m_{4}d)\\
&amp;=(m_{4} - (m_{3}(m_{2}n_{1} + m_{4}n_{2}))/(m_{1}n_{1} + m_{3}n_{2} - 1))(kb+ld)
\end{aligned}
\end{equation*} 
\]</span></p>
<p><span class="math display">\[
\begin{equation*}
\begin{aligned}
ia+jc&amp;=z^{新}_{1}/(m_{1} - (m_{2}(m_{1}n_{3} + m_{3}n_{4}))/(m_{2}n_{3} + m_{4}n_{4} - 1))\\
kf+lh &amp;= z^{新}_{2}/(m_{4} - (m_{3}(m_{2}n_{1} + m_{4}n_{2}))/(m_{1}n_{1} + m_{3}n_{2} - 1))\\
\end{aligned}
\end{equation*} 
\]</span></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/09/29/%E8%87%AA%E7%BC%96%E7%A0%81%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/09/29/%E8%87%AA%E7%BC%96%E7%A0%81%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">自编码神经网络学习笔记</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2022-09-29 19:28:17 / 修改时间：20:34:43" itemprop="dateCreated datePublished" datetime="2022-09-29T19:28:17+08:00">2022-09-29</time>
    </span>

  
    <span id="/2022/09/29/%E8%87%AA%E7%BC%96%E7%A0%81%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="post-meta-item leancloud_visitors" data-flag-title="自编码神经网络学习笔记" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span class="leancloud-visitors-count"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="自编码神经网络">自编码神经网络</h1>
<h2 id="前言">前言</h2>
<p>神经网络最大的卖点就是其端到端(end-to-end)的过程</p>
<p>无论是用于图像处理的CNN，还是用于自然语言处理的RNN都可以看做为一种类似编码解码的过程</p>
<h3 id="从编码-解码角度看cnn">从编码-解码角度看CNN</h3>
<figure>
<img src="/2022/09/29/%E8%87%AA%E7%BC%96%E7%A0%81%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/CNN.png" alt="CNN"><figcaption>CNN</figcaption>
</figure>
<p>在CNN中可以将编码-解码看做:</p>
<p><strong>编码器</strong>:将输入编程成中间表达形式(特征)</p>
<p><strong>解码器</strong>:将中间表示解码成输出</p>
<p>例如你将一只猫的图片当做模型的输入，首先图片将会经过一系列的隐藏层进行特征提取。</p>
<p>该过程就可以看做是一个编码的过程，及将一个原始的东西编码成为一个中间表达形式，其中间表达形式能够更加方便的使得机器进行学习。</p>
<p>经过一些列的特征提取后，将提取到的特征通过softmax回归进行识别。</p>
<p>该过程便是将前面隐藏层产生的中间形式进行解码输出。</p>
<h3 id="从编码-解码角度看rnn">从编码-解码角度看RNN</h3>
<figure>
<img src="/2022/09/29/%E8%87%AA%E7%BC%96%E7%A0%81%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/RNN.png" alt="RNN"><figcaption>RNN</figcaption>
</figure>
<p>在RNN中可以将编码-解码看成:</p>
<p><strong>编码器</strong>:将文本表示成向量</p>
<p><strong>解码器</strong>:向量表示成输出</p>
<h2 id="自编码神经网络-1">自编码神经网络</h2>
<h3 id="编码器-解码器架构">编码器-解码器架构</h3>
<p>编码器-解码器架构便是将一个模型如图分为两块 1. Encoder 2. Decoder <img src="/2022/09/29/%E8%87%AA%E7%BC%96%E7%A0%81%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/incode-decode.png" alt="编码器-解码器架构"></p>
<p>输入经过编码器处理后将其转变成一种中间状态(State)后经过解码器将其转变为输出</p>
<p>其中经过编码器处理后的中间状态将有助于机器进行学习(因为进行了筛选，等于只把重要信息保留，所以更有助于学习，就如PCA主成分分析的降维功效)</p>
<h3 id="自编码神经网络-2">自编码神经网络</h3>
<p>而所谓的自编码神经网络其实就是通过从原始数据中不断的提取重要信息，再利用得到的特征信息重新构建新的数据，而构建的新数据中包含了原始数据中重要的特征信息。其中中间状态是原始数据中的精髓</p>
<p>可以看出自编码神经网络重头到尾只用到了原始数据的输入信息，并没有用到原始数据的标签，所以自编码神经网络是一个无监督学习的模型</p>
<figure>
<img src="/2022/09/29/%E8%87%AA%E7%BC%96%E7%A0%81%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/AENN.png" alt="自编码神经网络模型结构图"><figcaption>自编码神经网络模型结构图</figcaption>
</figure>
<h3 id="训练过程">训练过程</h3>
<p>其本质上任然是神经网络，并且没有创造出任何特殊层，就只是模型结构的变化</p>
<p>因此训练过程任然按照神经网络的过程进行训练</p>
<h2 id="参考">参考</h2>
<pre><code>1. https://blog.csdn.net/hxxjxw/article/details/106869571?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E8%87%AA%E7%BC%96%E7%A0%81%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-3-106869571.142^v51^new_blog_pos_by_title,201^v3^add_ask&amp;spm=1018.2226.3001.4187
2. https://www.bilibili.com/video/BV1c54y1E7YP/?spm_id_from=333.999.0.0&amp;vd_source=bba5777f1f15698fba3ee38f0106b6e1
3. https://www.bilibili.com/video/BV1Vx411j78H/?spm_id_from=333.999.0.0&amp;vd_source=bba5777f1f15698fba3ee38f0106b6e1
4. https://zh.d2l.ai/chapter_recurrent-modern/encoder-decoder.html </code></pre>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/08/10/RCNN%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/08/10/RCNN%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">RCNN笔记</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-08-10 14:54:22" itemprop="dateCreated datePublished" datetime="2022-08-10T14:54:22+08:00">2022-08-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-08-14 15:25:45" itemprop="dateModified" datetime="2022-08-14T15:25:45+08:00">2022-08-14</time>
    </span>

  
    <span id="/2022/08/10/RCNN%E7%AC%94%E8%AE%B0/" class="post-meta-item leancloud_visitors" data-flag-title="RCNN笔记" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span class="leancloud-visitors-count"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="区域卷积神经网络">区域卷积神经网络</h1>
<h1 id="r-cnn基于区域的卷积神经网络">R-CNN（基于区域的卷积神经网络）</h1>
<ul>
<li>最早的检测模型</li>
</ul>
<figure>
<img src="/2022/08/10/RCNN%E7%AC%94%E8%AE%B0/1.png" alt="模型结构图"><figcaption>模型结构图</figcaption>
</figure>
<p>模型步骤:</p>
<ul>
<li><p>通过Selective search算法(一种启发式算法)来选择多个高质量的提议区域。将其获得的区域截成图片</p></li>
<li><p>通过一个预训练好的模型(图中两侧的CNN)来对其截取的图片进行特征提取</p></li>
<li><p>训练一个SVM对类别进行分类</p></li>
<li><p>训练一个线性模型来预测边缘框的偏移</p></li>
</ul>
<h2 id="由于选择的锚框的大小是不同的在这种情况下如何使这些大小不一的锚框变成一个batch">由于选择的锚框的大小是不同的，在这种情况下，如何使这些大小不一的锚框变成一个batch</h2>
<h2 id="roi-pooling兴趣区域池化层">RoI pooling（兴趣区域池化层）</h2>
<p><strong>R-CNN 中比较关键的层，作用是将大小不一的锚框变成统一的形状</strong></p>
<ul>
<li><p>给定一个锚框，先将其均匀地分割成 n * m 块，然后输出每块里的最大值，</p></li>
<li><p>这样的话，不管输入进来的锚框有多大，只要给定了 n 和 m 的值，总是输出 n<span class="math inline">\(\times\)</span>m 个</p></li>
<li><p>这样的话，不同大小的锚框就都可以变成同样的大小，然后就可以作为一个小批量</p></li>
</ul>
<figure>
<img src="/2022/08/10/RCNN%E7%AC%94%E8%AE%B0/2.png" alt="结构图"><figcaption>结构图</figcaption>
</figure>
<ul>
<li><p>左边输入框进入2 <span class="math inline">\(\times\)</span> 2 ROL池化层后</p></li>
<li><p>先均匀的分成 4块</p></li>
<li><p>左上 5 = max(0,1,4,5) 右上 6 = max(1,2,5,6)依次类推</p></li>
</ul>
<h2 id="兴趣区域池化层roi-pooing与一般的池化层的区别">兴趣区域池化层（RoI Pooing）与一般的池化层的区别</h2>
<ul>
<li><p>在一般的池化层中，通过设置池化窗口、填充和步幅的大小来间接控制输出形状</p></li>
<li><p>在兴趣区域池化层中，对每个区域的输出形状是可以直接指定的</p></li>
</ul>
<h2 id="r-cnn">R-CNN</h2>
<ul>
<li><p>R-CNN 模型通过预训练的卷积神经网络有效地抽取了图像特征</p></li>
<li><p>但是速度非常慢（如果从一张图片中选取了上千个提议区域，就需要上千次的卷积神经网络的前向传播来执行目标检测，计算量非常大）</p></li>
</ul>
<h1 id="fast-rcnn">Fast RCNN</h1>
<p>由于RCNN如果从一张图片中选取了上千个区域，就需要上千次的CNN提取特征，计算量非常大</p>
<p>其主要原因是在于</p>
<ul>
<li>R-CNN 对于每个提议区域，卷积神经网络的前向传播是独立的，没有共享计算（这些提议区域通常有重叠，独立的特征提取会导致重复计算）</li>
</ul>
<h2 id="fast-rcnn的改进">Fast RCNN的改进</h2>
<ul>
<li><p>首先对输入的一整张图片用CNN抽取特征</p></li>
<li><p>在用RCNN中的启发式搜索 锚框</p></li>
<li><p>搜索到原始图片上的锚框之后将其（按照一定的比例）映射到 CNN 的输出上</p></li>
<li><p>映射完锚框之后，再使用 RoI pooling 对 CNN 输出的 feature map 上的锚框进行特征抽取，生成固定长度的特征，之后再通过一个全连接层（这样就不需要使用SVM一个一个的操作，而是一次性操作了）对每个锚框进行预测：物体的类别和真实的边缘框的偏移</p></li>
</ul>
<figure>
<img src="/2022/08/10/RCNN%E7%AC%94%E8%AE%B0/3.png" alt="模型结构图"><figcaption>模型结构图</figcaption>
</figure>
<h2 id="总结">总结</h2>
<h3 id="fast-rcnn对于rcnn的改进">Fast RCNN对于RCNN的改进：</h3>
<ul>
<li><p>Fast R-CNN 中的 CNN 不再对每个锚框抽取特征，而是对整个图片进行特征的提取</p></li>
<li><p>使得锚框出现重复区域不需要重复获取特征</p></li>
<li><p>然后再在整张图片的feature中找出原图中锚框对应的特征，最后一起做预测</p></li>
</ul>
<h1 id="faster-rcnn">Faster RCNN</h1>
<ul>
<li><p>为了精确地检测目标结果，Fast R-CNN 模型通常需要在选择性搜索中生成大量的提议区域</p></li>
<li><p>因此，Faster R-CNN 提出将选择性搜索替换为区域提议网络（region proposal network，RPN），模型的其余部分保持不变，从而减少区域的生成数量，并保证目标检测的精度</p></li>
</ul>
<figure>
<img src="/2022/08/10/RCNN%E7%AC%94%E8%AE%B0/4.png" alt="模型结构图"><figcaption>模型结构图</figcaption>
</figure>
<h2 id="faster-rcnn模型">Faster RCNN模型</h2>
<ul>
<li><p>使用 RPN 神经网络来替代 selective search</p></li>
<li><p>RPN 的输入是 CNN 输出的 feature map，输出是一些比较高质量的锚框（可以理解为一个比较小而且比较粗糙的目标检测算法： CNN 的输出进入到 RPN 之后再做一次卷积，然后生成一些锚框（可以是 selective search 或者其他方法来生成初始的锚框）</p></li>
<li><p>再训练一个二分类问题：预测锚框是否框住了真实的物体以及锚框到真实的边缘框的偏移，最后使用 NMS 进行去重，使得锚框的数量变少</p></li>
</ul>
<h2 id="faster-rcnn总结">Faster RCNN总结</h2>
<ul>
<li><p>RPN 的作用是生成大量结果很差的锚框，然后进行预测，最终输出比较好的锚框供后面的网络使用（预测出来的比较好的锚框会进入 RoI pooling，后面的操作与 Fast R-CNN 类似)</p></li>
<li><p>Faster R-CNN 目前来说是用的比较多的算法，准确率比较高，但是速度比较慢</p></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/08/09/pytorch%E2%80%94%E2%80%941/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/08/09/pytorch%E2%80%94%E2%80%941/" class="post-title-link" itemprop="url">pytorch——1</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-08-09 18:36:32" itemprop="dateCreated datePublished" datetime="2022-08-09T18:36:32+08:00">2022-08-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-08-14 15:16:25" itemprop="dateModified" datetime="2022-08-14T15:16:25+08:00">2022-08-14</time>
    </span>

  
    <span id="/2022/08/09/pytorch%E2%80%94%E2%80%941/" class="post-meta-item leancloud_visitors" data-flag-title="pytorch——1" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span class="leancloud-visitors-count"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/05/28/%E6%89%8B%E5%86%99%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/05/28/%E6%89%8B%E5%86%99%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/" class="post-title-link" itemprop="url">手写多层感知机</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-28 18:14:28" itemprop="dateCreated datePublished" datetime="2022-05-28T18:14:28+08:00">2022-05-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-08-14 15:16:08" itemprop="dateModified" datetime="2022-08-14T15:16:08+08:00">2022-08-14</time>
    </span>

  
    <span id="/2022/05/28/%E6%89%8B%E5%86%99%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/" class="post-meta-item leancloud_visitors" data-flag-title="手写多层感知机" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span class="leancloud-visitors-count"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="激活函数">激活函数</h1>
<p>为了引入非线性运算，神经网络在每个层之间增加了一个按元素进行非线性运算的操作，也就是激活函数(Activation Function) 常见的激活函数有</p>
<h2 id="relu函数">ReLU函数</h2>
<h3 id="数学表达">数学表达</h3>
<p>ReLU（rectified linear unit）函数提供了一个很简单的非线性变换. <span class="math display">\[\operatorname{ReLU}(x)=\max (x, 0)\]</span> <img src="/2022/05/28/%E6%89%8B%E5%86%99%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/2.png" alt="ReLU"> 其导数为: <span class="math display">\[\left\{\begin{array}{ll}
1, &amp; x \geqslant 0 \\
0, &amp; x&lt;0
\end{array}\right.\]</span> <img src="/2022/05/28/%E6%89%8B%E5%86%99%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/3.png" alt="ReLU导数"></p>
<h3 id="代码实现">代码实现</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> nd</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">relu</span>(<span class="params">X</span>):</span><br><span class="line">    <span class="keyword">return</span> nd.maximum(X,<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def relu_prime(y):</span><br><span class="line">    z = nd.copy(y)</span><br><span class="line">    z[y&gt;0] = 1</span><br><span class="line">    z[y&lt;0] = 0</span><br><span class="line">    z[y == 0] = 1</span><br><span class="line">    return z</span><br></pre></td></tr></table></figure>
<h2 id="sigmoid">sigmoid</h2>
<h3 id="数学表达-1">数学表达</h3>
<p>sigmoid函数可以将元素的值变换到0和1之间： <span class="math display">\[\operatorname{sigmoid}(x)=\frac{1}{1+\exp (-x)}\]</span> <img src="/2022/05/28/%E6%89%8B%E5%86%99%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/4.png" alt="sigmoid"> 其导数为: <span class="math display">\[\operatorname{sigmoid}{ }^{\prime}(x)=\operatorname{sigmoid}(x)(1-\operatorname{sigmoid}(x))\]</span> <img src="/2022/05/28/%E6%89%8B%E5%86%99%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/5.png" alt="sigmoid导数"></p>
<h3 id="代码实现-1">代码实现</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">X</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>/(<span class="number">1</span>+nd.exp(-X))</span><br></pre></td></tr></table></figure>
<p>导数: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid_prime</span>(<span class="params">y</span>):</span><br><span class="line">    <span class="keyword">return</span> sigmoid(y)*(<span class="number">1</span> - sigmoid(y))</span><br></pre></td></tr></table></figure></p>
<hr>
<h1 id="前向传播反向传播">前向传播、反向传播</h1>
<h2 id="前项传播">前项传播</h2>
<p>前项传播(forward propagation或forward pass)是指：按照顺序(从输入层到输出层)计算和存储神经网络中每层的结果。</p>
<p>对于一个最简单(不含有偏置)的单隐藏层为 <embed src="手写多层感知机/1.png#pic_center"></p>
<p>我们假设输入是一个特征为<span class="math inline">\(\boldsymbol{x} \in \mathbb{R}^{d}\)</span>的样本输入，<span class="math inline">\(\boldsymbol{W}^{(h)} \in \mathbb{R}^{h \times d}\)</span>，则中间变量<span class="math inline">\(\boldsymbol{z} \in \mathbb{R}^{h}\)</span>可表示为: <span class="math display">\[\boldsymbol{z}=\boldsymbol{W}^{(1)} \boldsymbol{x}\]</span> 将其按元素进行激活函数<span class="math inline">\(\phi\)</span>运算后，将会得到隐藏层变量<span class="math inline">\(\boldsymbol{h}\in \mathbb{R}^{h }\)</span> <span class="math display">\[\boldsymbol{h}=\phi(\boldsymbol{z})\]</span> 假设输出层参数权重只有<span class="math inline">\(\boldsymbol{W}^{(o)} \in \mathbb{R}^{q \times h}\)</span>,则和隐藏层变量进行乘积可以得到输出层变量<span class="math inline">\(\boldsymbol{O}=\in \mathbb{R}^{q}\)</span> <span class="math display">\[\boldsymbol{o}=\boldsymbol{W}^{(o)} \boldsymbol{h}\]</span> 假设损失函数为<span class="math inline">\(\ell\)</span> , 且样本标签为<span class="math inline">\(y\)</span> , 可以计算出单个数据样本的损失项</p>
<p><span class="math display">\[L=\ell(\boldsymbol{o}, y)\]</span></p>
<p>在此，我们并不考虑正则项的加入，我们将其<span class="math inline">\(L\)</span>就作为我们有关给定数据样本的目标函数。 ___ 至此，正向传播过程结束</p>
<p>其代码实现十分简单:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">X,W1,W2,num_inputs</span>):</span><br><span class="line">    <span class="comment"># 将其输入拉成一个一维向量</span></span><br><span class="line">    X = X.reshape((-<span class="number">1</span>,num_inputs))</span><br><span class="line">    Z = nd.dot(X,W1)</span><br><span class="line">    <span class="comment"># 经过激活函数</span></span><br><span class="line">    h = sigmoid(Z)</span><br><span class="line">    o = nd.dot(h,W2)</span><br><span class="line">    <span class="keyword">return</span> o</span><br></pre></td></tr></table></figure>
<h2 id="反向传播">反向传播</h2>
<p>反向传播（backward propagation或backpropagation）指的是计算神经网络参数梯度的方法。 主要根据链式法则对目标函数求可学习参数的偏导，之后对其进行参数更新。</p>
<h3 id="数学推导">数学推导</h3>
<p>首先，目标函数对于输出层的梯度为<span class="math inline">\(\partial L / \partial \boldsymbol{o} \in \mathbb{R}^{q}\)</span></p>
<p>其次，计算最靠近输出层的模型参数梯度<span class="math inline">\(\partial L / \partial W^{(o)} \in \mathbb{R}^{q \times h}\)</span></p>
<p><span class="math display">\[\frac{\partial L}{\partial \boldsymbol{W}^{(o)}}=\frac{\partial L}{\partial \boldsymbol{o}}\cdot \frac{\partial \boldsymbol{o}}{\partial \boldsymbol{W}^{(o)}}=\frac{\partial L}{\partial \boldsymbol{o}} \boldsymbol{h}^{\top}\]</span></p>
<p>沿着输出层向隐藏层继续进行反向传播，隐藏层的变量梯度<span class="math inline">\(\partial L / \partial \boldsymbol{h} \in \mathbb{R}^{h}\)</span>:</p>
<p><span class="math display">\[\frac{\partial L}{\partial \boldsymbol{h}}=\frac{\partial L}{\partial \boldsymbol{o}}\cdot \frac{\partial \boldsymbol{o}}{\partial \boldsymbol{h}}=\boldsymbol{W}^{(o)^{\top}} \frac{\partial L}{\partial \boldsymbol{o}}\]</span></p>
<p>之后，因为激活函数是按照元素运算，所以对于<span class="math inline">\(\partial L / \partial \boldsymbol{z} \in \mathbb{R}^{h}\)</span>的计算，需要使用按照元素乘法:</p>
<p><span class="math display">\[\frac{\partial L}{\partial \boldsymbol{z}}=\frac{\partial L}{\partial \boldsymbol{h}}\cdot \frac{\partial \boldsymbol{h}}{\partial \boldsymbol{z}}=\frac{\partial L}{\partial \boldsymbol{h}} \odot \phi^{\prime}(\boldsymbol{z})\]</span></p>
<p>最后，可以计算出输入层模型参数的梯度<span class="math inline">\(\partial L / \partial W^{(h)} \in \mathbb{R}^{h \times d}\)</span></p>
<p><span class="math display">\[\frac{\partial L}{\partial \boldsymbol{W}^{(h)}}=\frac{\partial L}{\partial \boldsymbol{z}}\cdot \frac{\partial \boldsymbol{z}}{\partial \boldsymbol{W}^{(h)}}=\frac{\partial L}{\partial \boldsymbol{z}} \boldsymbol{x}^{\top}\]</span></p>
<p>以上推导过程在<strong>必要的</strong>时候根据两个输入形状，会将其输入进行转置或者互换位置进行相乘(<strong>就是以偏导的维度为准，根据实际的偏导维度调整上述式子中任意两个乘积的位置或者将其更改为其输入的偏置</strong>)</p>
<h3 id="代码实现-2">代码实现</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">backword</span>(<span class="params">self,dLdo,X,h,W1,W2</span>):</span><br><span class="line">    <span class="comment"># 传入损失函数对于输入层的梯度</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># h-&gt;o层</span></span><br><span class="line">    <span class="comment"># 根据梯度自行调节   </span></span><br><span class="line">    W2_grad = nd.dot(h.T,dLdo)</span><br><span class="line"></span><br><span class="line">    dLdh = nd.dot(dLdo,W2.T)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    dLdz = dLdh*sigmoid_prime(h)</span><br><span class="line">        </span><br><span class="line">    X = X.reshape((-<span class="number">1</span>,num_inputs))</span><br><span class="line">    <span class="comment"># 改过</span></span><br><span class="line">    W1_grad = nd.dot(X.T, dLdz)</span><br></pre></td></tr></table></figure>
<h3 id="损失函数的导数">损失函数的导数</h3>
<p>上述过程介绍了整个网络中梯度的传递过程，只要将损失函数对于输出层梯度带入即可算出各个可学习参数的梯度，依次进行梯度更新。</p>
<p>大体上损失函数根据实际问题可以分为两类 - 线性回归 - 分类</p>
<h4 id="线性回归">线性回归</h4>
<p>回归（regression）是能为一个或多个自变量与因变量之间关系建模的一类方法。线性回归输出是一个连续值，因此适用于回归问题。</p>
<p>其中回归问题中最常用的损失函数就是L2损失:</p>
<p><span class="math display">\[\ell=\frac{1}{2}\left(\hat{y}^{(i)}-y^{(i)}\right)^{2}\]</span></p>
<p>其导数为: <span class="math display">\[\ell&#39;=\left(\hat{y}^{(i)}-y^{(i)}\right)\]</span></p>
<h4 id="分类问题">分类问题</h4>
<p>线性回归模型适用于输出为连续值，而分类问题适用于像图像类别这样的离散值。</p>
<p>对于离散值预测问题，可以使用诸如softmax回归在内的分类模型。和线性回归不同，softmax回归的输出单元从一个变成了多个，且引入了softmax运算使输出更适合离散值的预测和训练。</p>
<p>为了得到一个模型不同类别的预测结果，会将其设置一个阀值，如选择概率最大的标签。</p>
<p>例如假设训练数据集中真实的标签为狗，猫或鸡(假设可以用4像素表示出这三种动物)，这些标签分别对应的离散值为<span class="math inline">\(y_1,y_2,y_3\)</span></p>
<p>通常用离散的数值来表示类别。例如<span class="math inline">\(y_1 = 1,y_2 = 2,y_3 = 3\)</span>.一张图片的标签为1,2,和3这三个数值中的一个。</p>
<p><strong>虽然我们仍然可以通过回归模型来进行建模，将预测值就近点化到1,2和3这三个离散值之一，但这种连续值到离散值的转换通常会影响到分类质量</strong></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/05/28/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Yang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/05/28/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/" class="post-title-link" itemprop="url">多层感知机-笔记</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-05-28 14:06:02" itemprop="dateCreated datePublished" datetime="2022-05-28T14:06:02+08:00">2022-05-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-06-06 18:58:22" itemprop="dateModified" datetime="2022-06-06T18:58:22+08:00">2022-06-06</time>
    </span>

  
    <span id="/2022/05/28/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/" class="post-meta-item leancloud_visitors" data-flag-title="多层感知机-笔记" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span class="leancloud-visitors-count"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="multilayer-perceptionsmlp">Multilayer perceptions(MLP)</h1>
<h2 id="单层感知机">单层感知机</h2>
<p>单层感知机又叫做<strong>稠密层 Dense</strong>(<strong>全连接层</strong>，<strong>线性层</strong>) 主要有两个可学习参数，主要有两个可学习参数:<span class="math inline">\(\mathbf{W} \in \mathbb{R}^{m \times n},\mathbf{b} \in \mathbb{R}^{m}\)</span>,输入数据为<span class="math inline">\(\mathbf{x}\in \mathbb{R}^{n}\)</span> 则其输出为:<span class="math inline">\(\mathbf{y}=\mathbf{W} \mathbf{x}+\mathbf{b} \in \mathbb{R}^{m}\)</span> 我们可以将线性回归和Softmax回归总结如下: - 线性回归可以看做是只有1个输出的全连接层 - Softmax回归可以看做是有<span class="math inline">\(\mathbb{m}\)</span>个输出(<span class="math inline">\(\mathbb{m}\)</span>是分类的类别数)进行Softmax运算</p>
<h2 id="多层感知机">多层感知机</h2>
<p>因为单层感知机是一个线性运算，所以简单的单个感知机叠加没法处理非线性问题(如&quot;异或&quot;问题)。 为了引入非线性运算，神经网络在每个层之间增加了一个按元素进行非线性运算的操作，也就是激活函数(Activation Function)</p>
<h3 id="常见的激活函数">常见的激活函数</h3>
<h4 id="sigmoid">sigmoid</h4>
<p><span class="math display">\[\operatorname{sigmoid}(x)=\frac{1}{1+\exp (-x)}\]</span></p>
<h4 id="relu">ReLU</h4>
<p><span class="math display">\[\operatorname{ReLU}(x)=\max (x,0)\]</span></p>
<h3 id="mlp">MLP</h3>
<p>而所谓的多层感知机就是将多个全连接层堆叠，全连接层之间通过激活函数链接。</p>
<p>常见的单隐藏层和三层隐藏层的网络结构图如图所示(有颜色的是隐藏层)</p>
<figure>
<img src="/2022/05/28/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/2.png" alt="网络结构图"><figcaption>网络结构图</figcaption>
</figure>
<p>其中隐藏层个数的选择和隐藏层输出维度的选择都是超参数(需要自己设定)。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yang</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.0/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  


  <script class="next-config" data-name="leancloud_visitors" type="application/json">{"enable":true,"app_id":null,"app_key":null,"server_url":null,"security":false}</script>
  <script src="/js/third-party/statistics/lean-analytics.js"></script>


  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
